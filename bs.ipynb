{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFUnfYVIiJGSAxb6Bg2+Ui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e77921b91617488b8910ec9b582e52bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10772555e083435582ed76dc3a8552db",
              "IPY_MODEL_46bb323edb5b420ca800f2421f375e60",
              "IPY_MODEL_9fed6b23cccc4890bdf0cd65f14fbd8f"
            ],
            "layout": "IPY_MODEL_b24c9689d0b94f39bf7cea8223ac5e58"
          }
        },
        "10772555e083435582ed76dc3a8552db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4494067f3e1a458081cc132da91d691e",
            "placeholder": "​",
            "style": "IPY_MODEL_8eced0aa6c694730a612a930ce1f8c3d",
            "value": "Map: 100%"
          }
        },
        "46bb323edb5b420ca800f2421f375e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bf4edb10a01414a9ee5bd63ed4ddfe9",
            "max": 33203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83ccc69554fa4e01bc4b1e73a069dd06",
            "value": 33203
          }
        },
        "9fed6b23cccc4890bdf0cd65f14fbd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896970a5c884468db34566dcb798bc23",
            "placeholder": "​",
            "style": "IPY_MODEL_e84bac818a2f49e2b01d247479cfb676",
            "value": " 33203/33203 [00:02&lt;00:00, 14974.23 examples/s]"
          }
        },
        "b24c9689d0b94f39bf7cea8223ac5e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4494067f3e1a458081cc132da91d691e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eced0aa6c694730a612a930ce1f8c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bf4edb10a01414a9ee5bd63ed4ddfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ccc69554fa4e01bc4b1e73a069dd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "896970a5c884468db34566dcb798bc23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84bac818a2f49e2b01d247479cfb676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f58af78f7754010992a1d5240d8d8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_015796b5ed234f1289a7a1fb8e66fd95",
              "IPY_MODEL_70df674cc2b84c09b2c64fe5d0cf91a0",
              "IPY_MODEL_0e2256d0b1404afeba4bfa5a7efa5c19"
            ],
            "layout": "IPY_MODEL_be2710febcee40b3858fa34f68e54cfd"
          }
        },
        "015796b5ed234f1289a7a1fb8e66fd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644e473f7d3e461abb89990fc0c8039a",
            "placeholder": "​",
            "style": "IPY_MODEL_af5f2fb4ce4f4efcbda10df18e4ecd39",
            "value": "Map: 100%"
          }
        },
        "70df674cc2b84c09b2c64fe5d0cf91a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b90323b805444c987cd75bb023d8f5d",
            "max": 33203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa8e445617414d729abc88022cd81a74",
            "value": 33203
          }
        },
        "0e2256d0b1404afeba4bfa5a7efa5c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4509bfd09c42bcb90cdd5a9e311dd8",
            "placeholder": "​",
            "style": "IPY_MODEL_c8a50cb755584eb9886ece6488ac4c64",
            "value": " 33203/33203 [00:27&lt;00:00, 1311.17 examples/s]"
          }
        },
        "be2710febcee40b3858fa34f68e54cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644e473f7d3e461abb89990fc0c8039a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af5f2fb4ce4f4efcbda10df18e4ecd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b90323b805444c987cd75bb023d8f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8e445617414d729abc88022cd81a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f4509bfd09c42bcb90cdd5a9e311dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a50cb755584eb9886ece6488ac4c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkalvakotamath/gpt_instruct/blob/main/bs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjdL-6KVUjmL",
        "outputId": "a24b48f9-3aad-4344-e9dc-b37584b7d79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from transformers import PreTrainedTokenizerBase\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "class InstructGPT:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = 'gpt2-medium',\n",
        "        max_length: int = 420\n",
        "    ):\n",
        "        self.model_name = model_name\n",
        "        self.max_length = max_length\n",
        "\n",
        "\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self.model.config.pad_token_id = self.tokenizer.pad_token_id\n",
        "\n",
        "\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        # Change this to a better dataset because this one sucks\n",
        "        dataset = load_dataset(\"Dahoas/instruct-synthetic-prompt-responses\")\n",
        "\n",
        "        # Combine prompts\n",
        "        def combine_prompt_response(example):\n",
        "            full_text = f\"{example['prompt']} {self.tokenizer.eos_token} {example['response']}\"\n",
        "            return {'text': full_text}\n",
        "        dataset = dataset.map(combine_prompt_response, remove_columns=dataset['train'].column_names)\n",
        "        return dataset\n",
        "\n",
        "    def tokenize_function(self, examples):\n",
        "        return self.tokenizer(\n",
        "            examples['text'],\n",
        "            truncation=True,\n",
        "\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length'\n",
        "        )\n",
        "\n",
        "    def prepare_training_data(self, test_size: float = 0.1):\n",
        "\n",
        "        tokenized_datasets = self.dataset.map(\n",
        "            self.tokenize_function,\n",
        "            remove_columns=self.dataset['train'].column_names,\n",
        "\n",
        "            batched=True,\n",
        "        )\n",
        "\n",
        "        # Split into train and validation\n",
        "        tokenized_datasets = tokenized_datasets['train'].train_test_split(test_size=test_size)\n",
        "\n",
        "        return tokenized_datasets\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        output_dir: str = './instruct-gpt2-model',\n",
        "        learning_rate: float = 5e-5,\n",
        "        batch_size: int = 8,\n",
        "        num_train_epochs: int = 1, # not really sure about this stuff yet, may want to tweak this later\n",
        "    ):\n",
        "\n",
        "        weight_decay=0.01\n",
        "\n",
        "        self.dataset = self.prepare_dataset() # Call prepare_dataset to initialize self.dataset\n",
        "        tokenized_datasets = self.prepare_training_data()\n",
        "\n",
        "        data_collator = DataCollatorForLanguageModeling(\n",
        "            tokenizer=self.tokenizer,\n",
        "            mlm=False\n",
        "        )\n",
        "        # Training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            fp16=True,\n",
        "            output_dir=output_dir,\n",
        "            overwrite_output_dir=True,\n",
        "            num_train_epochs=num_train_epochs,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            eval_steps=100,\n",
        "            prediction_loss_only=True,\n",
        "            learning_rate=learning_rate,\n",
        "            weight_decay=weight_decay\n",
        "        )\n",
        "\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=tokenized_datasets['train'],\n",
        "            eval_dataset=tokenized_datasets['test'],\n",
        "            data_collator=data_collator,\n",
        "        )\n",
        "\n",
        "\n",
        "        trainer.train()\n",
        "        trainer.save_model()\n",
        "\n",
        "        # Stuff from Claude because I apparently messed up a bunch of things\n",
        "    def generate_text(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        max_length: int = 420,\n",
        "        temperature: float = 0.5,\n",
        "        top_p: float = 0.9\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate text using trained model\n",
        "\n",
        "        Args:\n",
        "            prompt (str): Input prompt\n",
        "            max_length (int): Maximum generation length\n",
        "            temperature (float): Sampling temperature\n",
        "            top_p (float): Nucleus sampling threshold\n",
        "\n",
        "        Returns:\n",
        "            Generated text\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(device)\n",
        "\n",
        "        input_ids = self.tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "        output = self.model.generate(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            no_repeat_ngram_size=2,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "        return self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    instruct_trainer = InstructGPT()\n",
        "    instruct_trainer.train(\n",
        "        output_dir='./instruct-gpt2-model',\n",
        "        learning_rate=5e-5,\n",
        "        batch_size=8,\n",
        "        num_train_epochs=1\n",
        "    )\n",
        "\n",
        "    prompt = \"Give me a few good flirts and flirtatious texts to send to my girlfriend\"\n",
        "    generated_text = instruct_trainer.generate_text(prompt)\n",
        "    print(\"Response::\", generated_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "IcJj8J2M7kCS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775,
          "referenced_widgets": [
            "e77921b91617488b8910ec9b582e52bd",
            "10772555e083435582ed76dc3a8552db",
            "46bb323edb5b420ca800f2421f375e60",
            "9fed6b23cccc4890bdf0cd65f14fbd8f",
            "b24c9689d0b94f39bf7cea8223ac5e58",
            "4494067f3e1a458081cc132da91d691e",
            "8eced0aa6c694730a612a930ce1f8c3d",
            "9bf4edb10a01414a9ee5bd63ed4ddfe9",
            "83ccc69554fa4e01bc4b1e73a069dd06",
            "896970a5c884468db34566dcb798bc23",
            "e84bac818a2f49e2b01d247479cfb676",
            "6f58af78f7754010992a1d5240d8d8fb",
            "015796b5ed234f1289a7a1fb8e66fd95",
            "70df674cc2b84c09b2c64fe5d0cf91a0",
            "0e2256d0b1404afeba4bfa5a7efa5c19",
            "be2710febcee40b3858fa34f68e54cfd",
            "644e473f7d3e461abb89990fc0c8039a",
            "af5f2fb4ce4f4efcbda10df18e4ecd39",
            "5b90323b805444c987cd75bb023d8f5d",
            "fa8e445617414d729abc88022cd81a74",
            "0f4509bfd09c42bcb90cdd5a9e311dd8",
            "c8a50cb755584eb9886ece6488ac4c64"
          ]
        },
        "outputId": "ce577424-c8eb-43d2-ea2a-206dc3778ec4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/33203 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e77921b91617488b8910ec9b582e52bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/33203 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f58af78f7754010992a1d5240d8d8fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquantum_vaibhav\u001b[0m (\u001b[33mquantum_vaibhav-bayesian-group\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241124_175821-g6pdf1jl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/quantum_vaibhav-bayesian-group/huggingface/runs/g6pdf1jl' target=\"_blank\">./instruct-gpt2-model</a></strong> to <a href='https://wandb.ai/quantum_vaibhav-bayesian-group/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/quantum_vaibhav-bayesian-group/huggingface' target=\"_blank\">https://wandb.ai/quantum_vaibhav-bayesian-group/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/quantum_vaibhav-bayesian-group/huggingface/runs/g6pdf1jl' target=\"_blank\">https://wandb.ai/quantum_vaibhav-bayesian-group/huggingface/runs/g6pdf1jl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3736' max='3736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3736/3736 1:04:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.802900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.674100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.643800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.617500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.595900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.575900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.558500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:: Give me a few good flirts and flirtatious texts to send to my girlfriend.  \n",
            "\n",
            "1. \"Hey, how are you doing today? Can you tell me about the day's activities? \n",
            "\n",
            " \t\t  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50 51  52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_chat(model_path='./instruct-gpt2-model'):\n",
        "    \"\"\"\n",
        "    Interactive chat interface for the trained InstructGPT model.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the trained model\n",
        "    \"\"\"\n",
        "    # Initialize model with trained weights\n",
        "    chatbot = InstructGPT()\n",
        "    try:\n",
        "        chatbot.model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "        chatbot.model.eval()  # Set to evaluation mode\n",
        "        print(\"Model loaded successfully from\", model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"Falling back to base GPT-2 model\")\n",
        "\n",
        "    print(\"\\nInteractive Chat Session\")\n",
        "    print(\"Enter 'quit', 'exit', or press Ctrl+C to end the conversation\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Chat loop\n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_input = input(\"\\nYou: \").strip()\n",
        "\n",
        "            # Check for exit commands\n",
        "            if user_input.lower() in ['quit', 'exit']:\n",
        "                print(\"\\nEnding chat session...\")\n",
        "                break\n",
        "\n",
        "            if not user_input:\n",
        "                print(\"Please enter a prompt!\")\n",
        "                continue\n",
        "\n",
        "            # Generate response\n",
        "            print(\"\\nGenerating response...\")\n",
        "            response = chatbot.generate_text(\n",
        "                prompt=user_input,\n",
        "                temperature=0.7,  # Slightly higher temperature for more creative responses\n",
        "                top_p=0.9,\n",
        "                max_length=150  # Shorter responses for interactive chat\n",
        "            )\n",
        "\n",
        "            # Print response\n",
        "            print(\"\\nBot:\", response.strip())\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nEnding chat session...\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError occurred: {e}\")\n",
        "            print(\"Please try again!\")\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    interactive_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P979UG0DkUcR",
        "outputId": "8a77365c-8595-4f2d-faae-a8178b7eedc2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully from ./instruct-gpt2-model\n",
            "\n",
            "Interactive Chat Session\n",
            "Enter 'quit', 'exit', or press Ctrl+C to end the conversation\n",
            "==================================================\n",
            "\n",
            "You: Hi give me a story\n",
            "\n",
            "Generating response...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bot: Hi give me a story about how I went to college and how it changed my life\n",
            "\n",
            " \t\t  \n",
            "I went into college as a full-time student in 2000. I was studying for my final exams and had no idea that I would be taking on a major in Psychology. It was an exciting time to be a student and I could not have been more excited. However, things started to go wrong soon after I started classes. My grades started plummeting and my workload increased dramatically. The school administration was extremely difficult to deal with and it became increasingly difficult for me to complete my studies. In the end, I had to take a leave of absence and then a year to recover from my illness. With all of my work and\n",
            "\n",
            "You: Hi, how are you?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating response...\n",
            "\n",
            "Bot: Hi, how are you?\n",
            "\n",
            " \t\t  \n",
            "I'm doing great! I'm feeling very good about my new job and excited to get started. I want to thank you for taking the time to read my resume. It's a great way to make sure I am speaking the truth about myself and my qualifications. Good luck!\n",
            "\n",
            "\n",
            "Sincerely, \n",
            "\n",
            "[Your Name] [Hiring Company]\n",
            "[Company Name Here] [Company Email Address]\n",
            "\n",
            "1  Contact me at [company name] with any questions or comments.  [Name of Company],  Can you help me find a job for me?  I'd be happy to help.\n",
            "2  If you're interested in a career change,\n",
            "\n",
            "You: No fuck\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating response...\n",
            "\n",
            "Bot: No fuck you!\" I thought to myself as I walked down the street.\n",
            "\n",
            " \t\t  \n",
            "It was a moment of clarity. I had decided to leave my partner and come to the conclusion that I was not the right person for this relationship. \n",
            "\n",
            "\t\n",
            "I don't know if it was the clarity or the anger, but the decision to walk away from my life and pursue a new relationship made me feel like I owed her something. It felt like a relief to finally have an open conversation with someone. Afterward, I went home and was thankful for the time I spent with my new partner. She was someone who truly understood the meaning of life, and I have been thankful to her ever since. The lesson of this\n",
            "\n",
            "You: Write a ltetter to my boss XYZ saying I am fine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating response...\n",
            "\n",
            "Bot: Write a ltetter to my boss XYZ saying I am fine. Can you help me out with a job search?  \n",
            "\n",
            " \t\t \n",
            "Sure, I can help you out. What are some tips for finding a good job? Start by researching the company and the position. Once you have a better understanding of the job, you can start to tailor your resume and cover letter to the role. Make sure to include relevant skills and experience, and proof of your qualifications. You may also want to reach out to your supervisor directly to inquire about the opportunity. Finally, don't forget to thank them for their time and consideration. Good luck!  With the right job searching strategy, there's no reason why you won't find\n",
            "\n",
            "You: I already found a job numbnut\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating response...\n",
            "\n",
            "Bot: I already found a job numbnut, but I'm not sure if I should start yet. Can you help me get a better understanding of the job market?  \n",
            "\n",
            " \t\t \n",
            "Sure! What are some of your best tips for becoming a successful entrepreneur? Start by researching the market, understanding the current trends and potential opportunities, and creating a detailed plan for how you plan to reach your goals. Once you have an idea of what you want to achieve, create a budget and set aside time to create and manage your business. Be sure to plan ahead and create contingency plans for unexpected events. Finally, practice good communication and communication skills. Good luck!  With the right strategy, you'll be well on your way to becoming\n",
            "\n",
            "You: We finish each other's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating response...\n",
            "\n",
            "Bot: We finish each other's sentences and start to talk.  \n",
            "\n",
            "I'm going to the beach today. What are your plans? \n",
            "\n",
            " \t\t\n",
            "My plans are to go to a nearby beach and enjoy the sun. Is there anything I can do to help you plan?\n",
            " My plan is to take a few minutes to relax and soak up the ocean breeze. Do you know any good activities I could do?\n",
            "\n",
            "\t  My plan for the day is for me to hike and explore. How about a hike to an isolated spot? I'm sure I have something you could try.\n",
            "\tMy next plan would be to explore the local area. There are lots of outdoor activities and activities that you can take part in\n",
            "\n",
            "You: Explain BRST quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating response...\n",
            "\n",
            "Bot: Explain BRST quantization and how it works\n",
            "\n",
            " \t\t  \n",
            "Quantization is the process of taking the sum of two or more variables and dividing it by the total number of variables. It is used to calculate the average or mean of a range of values, or to divide a series of numbers into smaller and smaller groups. The key concept of BRT is to use the BRTS (Bi-weekly Trained Ratio) to determine the expected return on investments (ROI) of each investment. BRTs can be expressed as an average of the two variables in the series, with the upper and lower bounds being equal. For example, if the variables are 1, 2, 3 and 4, the value 1 + 2 =\n",
            "\n",
            "You: What is 2+2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating response...\n",
            "\n",
            "Bot: What is 2+2=5?\n",
            "\n",
            " \t\t   1  2 + 2 = 5 \n",
            "\t1  3  4 = 6 \n",
            "\n",
            "\t2  5 = 7  (2 + 3)  = 9  6 + 4  + 5\n",
            "  The answer to this question is: 2 equals 5. Therefore, 2 equal 5 means that 3 is equal to 6. 6 is also equal, so 6 equals 7. Finally, 7 equals 9. Thus, 3 equals 6 and 4 equals 3. This means 3 and 6 are equal.  Therefore 3 = 3, 6 = 4, and 9 = 8. So, the answer is that 2 is 5, but 3 does not equal 6, 4 does,\n",
            "\n",
            "\n",
            "Ending chat session...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAMKyXXySg4J",
        "outputId": "7e4517a0-e8b6-4218-b186-714c89ab244c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ]
    }
  ]
}